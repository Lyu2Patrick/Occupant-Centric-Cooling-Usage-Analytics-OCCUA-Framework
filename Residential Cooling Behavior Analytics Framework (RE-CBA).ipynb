{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ef872-f024-44a2-a5f3-2e4859a0ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef3e6a9-ecb2-4af8-bd4c-f40e838fd966",
   "metadata": {},
   "source": [
    "## Raw data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5d358-5904-422c-9cd7-43ecde808ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(file_path):\n",
    "    # Read the Excel file\n",
    "    df_cleaned = pd.read_excel(file_path)\n",
    "\n",
    "    # Fill missing values based on time\n",
    "    def fill_missing_values_based_on_time(dataframe):\n",
    "        dataframe['rawtime'] = pd.to_datetime(dataframe['rawtime'])\n",
    "        for index, row in dataframe.iterrows():\n",
    "            if row.isnull().any():\n",
    "                prev_row = dataframe.iloc[index - 1] if index - 1 >= 0 else None\n",
    "                next_row = dataframe.iloc[index + 1] if index + 1 < len(dataframe) else None\n",
    "                for col in dataframe.columns:\n",
    "                    if pd.isnull(row[col]):\n",
    "                        if prev_row is not None and next_row is not None:\n",
    "                            prev_diff = abs(row['rawtime'] - prev_row['rawtime'])\n",
    "                            next_diff = abs(row['rawtime'] - next_row['rawtime'])\n",
    "                            if prev_diff < next_diff:\n",
    "                                dataframe.at[index, col] = prev_row[col]\n",
    "                            else:\n",
    "                                dataframe.at[index, col] = next_row[col]\n",
    "                        elif prev_row is not None:\n",
    "                            dataframe.at[index, col] = prev_row[col]\n",
    "                        elif next_row is not None:\n",
    "                            dataframe.at[index, col] = next_row[col]\n",
    "        return dataframe\n",
    "\n",
    "    df_filled = fill_missing_values_based_on_time(df_cleaned)\n",
    "\n",
    "    # Convert rawtime to \"YYYY-MM-DD HH:MM\" format\n",
    "    df_filled['rawtime'] = df_filled['rawtime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Check for duplicate timestamps\n",
    "    def check_duplicate_timestamps(dataframe):\n",
    "        duplicate_counts = dataframe['rawtime'].value_counts()\n",
    "        duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "        if not duplicates.empty:\n",
    "            print(f\"There are {duplicates.sum()} duplicate timestamps. The first duplicate value will be removed.\")\n",
    "        return duplicates\n",
    "\n",
    "    duplicates_info = check_duplicate_timestamps(df_filled)\n",
    "\n",
    "    # Remove the first occurrence of duplicate timestamps\n",
    "    def remove_first_duplicate_and_recheck(dataframe):\n",
    "        duplicate_timestamps = dataframe['rawtime'][dataframe['rawtime'].duplicated(keep='first')]\n",
    "        dataframe_cleaned = dataframe.drop(duplicate_timestamps.index)\n",
    "        duplicate_counts = dataframe_cleaned['rawtime'].value_counts()\n",
    "        duplicates_after_removal = duplicate_counts[duplicate_counts > 1]\n",
    "        if duplicates_after_removal.empty:\n",
    "            print(\"Processing complete, no duplicate timestamps remain.\")\n",
    "        else:\n",
    "            print(f\"There are still {duplicates_after_removal.sum()} duplicate timestamps remaining.\")\n",
    "        return dataframe_cleaned\n",
    "\n",
    "    df_cleaned_final = remove_first_duplicate_and_recheck(df_filled)\n",
    "\n",
    "    # Insert missing rows with ID as the first column\n",
    "    def insert_missing_rows_with_id_first(dataframe):\n",
    "        dataframe['rawtime'] = pd.to_datetime(dataframe['rawtime'])\n",
    "        full_time_range = pd.date_range(start=dataframe['rawtime'].min(), end=dataframe['rawtime'].max(), freq='T')\n",
    "        df_full = pd.DataFrame({'rawtime': full_time_range})\n",
    "        df_merged = pd.merge(df_full, dataframe, on='rawtime', how='left')\n",
    "        df_merged['ID'] = dataframe['ID'].iloc[0]\n",
    "        df_merged['rawtime'] = df_merged['rawtime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "        columns_order = ['ID', 'rawtime'] + [col for col in df_merged.columns if col not in ['ID', 'rawtime']]\n",
    "        return df_merged[columns_order]\n",
    "\n",
    "    df_with_inserted_rows = insert_missing_rows_with_id_first(df_cleaned_final)\n",
    "\n",
    "    # Fill the 'Operational_status' column with the previous value\n",
    "    def fill_previous_value_for_column(dataframe, column_name):\n",
    "        dataframe[column_name] = dataframe[column_name].fillna(method='ffill')\n",
    "        return dataframe\n",
    "\n",
    "    df_filled_with_previous = fill_previous_value_for_column(df_with_inserted_rows, 'Operational_status')\n",
    "    df_filled_with_previous = fill_previous_value_for_column(df_with_inserted_rows, 'City')\n",
    "    df_filled_with_previous = fill_previous_value_for_column(df_with_inserted_rows, 'Mode')\n",
    "    # Interpolate 'Tin' and 'Tout' and round to 1 decimal place\n",
    "    def fill_with_interpolation_and_rounding(dataframe, columns, decimal_places=1):\n",
    "        dataframe[columns] = dataframe[columns].interpolate(method='linear', limit_direction='both').round(decimal_places)\n",
    "        return dataframe\n",
    "\n",
    "    df_filled_with_rounded_interpolation = fill_with_interpolation_and_rounding(df_filled_with_previous, ['Tin', 'Tout'], decimal_places=1)\n",
    "\n",
    "    # Fill 'Setpoint' column with the previous value\n",
    "    df_filled_with_final_adjustments = fill_previous_value_for_column(df_filled_with_rounded_interpolation, 'Setpoint')\n",
    "\n",
    "    # Function to count the number of shutdown cycles\n",
    "    def count_shutdown_cycles(dataframe, column_name):\n",
    "        shutdown_cycles = 0\n",
    "        in_shutdown = False\n",
    "    \n",
    "        for i in range(len(dataframe)):\n",
    "            current_status = dataframe.iloc[i][column_name]\n",
    "            if current_status == 0 and not in_shutdown:\n",
    "                in_shutdown = True  # Start of a shutdown cycle\n",
    "            elif current_status == 1 and in_shutdown:\n",
    "                shutdown_cycles += 1  # End of a shutdown cycle\n",
    "                in_shutdown = False  # Reset for the next cycle   \n",
    "        return shutdown_cycles\n",
    "    # Apply the function to count shutdown cycles in 'Operational_status'\n",
    "    shutdown_cycles_count = count_shutdown_cycles(df_filled_with_final_adjustments, 'Operational_status')\n",
    "    \n",
    "    # Display the result\n",
    "    print(f\"There are {shutdown_cycles_count} shutdown cycles.\")\n",
    "\n",
    "    # Function to replace temperature values with 'no_records' for each shutdown cycle\n",
    "    def replace_temperatures_in_shutdown_cycles(dataframe, column_name, temperature_columns):\n",
    "        in_shutdown = False\n",
    "        shutdown_start = None\n",
    "    \n",
    "        for i in range(len(dataframe)):\n",
    "            current_status = dataframe.iloc[i][column_name]\n",
    "        \n",
    "            if current_status == 0 and not in_shutdown:\n",
    "                # Mark the start of the shutdown cycle\n",
    "                in_shutdown = True\n",
    "                shutdown_start = i\n",
    "            elif current_status == 1 and in_shutdown:\n",
    "                # End of the shutdown cycle, process the rows\n",
    "                if shutdown_start is not None and (i - shutdown_start) > 1:\n",
    "                    # Replace values from the second 'Operational_status' == 0 until the last one\n",
    "                    dataframe.loc[shutdown_start + 1:i - 1, temperature_columns] = 'no_records'\n",
    "                # Reset for the next cycle\n",
    "                in_shutdown = False\n",
    "                shutdown_start = None\n",
    "\n",
    "        return dataframe\n",
    "    temperature_columns_to_replace = ['Setpoint', 'Tin', 'Tout']\n",
    "    df_replaced_temperatures = replace_temperatures_in_shutdown_cycles(df_filled_with_final_adjustments, 'Operational_status', temperature_columns_to_replace)\n",
    "\n",
    "    # Add the \"On/Off action\" column\n",
    "    def add_switch_action_column(dataframe, status_column):\n",
    "        dataframe['On/OFF'] = ''\n",
    "        for i in range(len(dataframe) - 1):\n",
    "            current_status = dataframe.iloc[i][status_column]\n",
    "            next_status = dataframe.iloc[i + 1][status_column]\n",
    "            if current_status == 0 and next_status == 1:\n",
    "                dataframe.at[i + 1, 'On/OFF'] = 'ON'\n",
    "            elif current_status == 1 and next_status == 0:\n",
    "                dataframe.at[i + 1, 'On/OFF'] = 'OFF'\n",
    "        return dataframe\n",
    "\n",
    "    df_with_switch_action = add_switch_action_column(df_replaced_temperatures, 'Operational_status')\n",
    "\n",
    "    # Add the \"Setpoint adjustment\" column\n",
    "    def add_temperature_action_column_with_handling(dataframe, temp_column):\n",
    "        dataframe['Setpoint adjustment'] = ''\n",
    "        for i in range(len(dataframe) - 1):\n",
    "            current_temp = dataframe.iloc[i][temp_column]\n",
    "            next_temp = dataframe.iloc[i + 1][temp_column]\n",
    "            if pd.api.types.is_numeric_dtype(type(current_temp)) and pd.api.types.is_numeric_dtype(type(next_temp)):\n",
    "                if next_temp > current_temp:\n",
    "                    dataframe.at[i + 1, 'Setpoint adjustment'] = 'Upper'\n",
    "                elif next_temp < current_temp:\n",
    "                    dataframe.at[i + 1, 'Setpoint adjustment'] = 'Lower'\n",
    "        return dataframe\n",
    "\n",
    "    df_final = add_temperature_action_column_with_handling(df_with_switch_action, 'Setpoint')\n",
    "\n",
    "    # Display the final dataframe\n",
    "    display(df_final)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4da44-91fa-48d3-8da9-7ffcda09a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=process_dataframe(\"83562883812609_example.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30594f49-d31f-4a16-a30c-5d53375b3c24",
   "metadata": {},
   "source": [
    "## Usage scenario analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f48f5-7379-4eb1-8513-5685b111c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ac_data(data):\n",
    "    # Convert rawtime to datetime format\n",
    "    data['rawtime'] = pd.to_datetime(data['rawtime'])\n",
    "\n",
    "    # Group by hour, calculating the total minutes each air conditioner was on per hour\n",
    "    data['hour'] = data['rawtime'].dt.floor('H')\n",
    "    hourly_data = data.groupby(['ID', 'hour'])['Operational_status'].sum().reset_index()\n",
    "    hourly_data['Operational_status'] = hourly_data['Operational_status'].clip(upper=60)\n",
    "\n",
    "    # Define the night and day hours\n",
    "    night_hours = [22, 23, 0, 1, 2, 3, 4, 5, 6, 7]\n",
    "    day_hours = list(set(range(24)) - set(night_hours))\n",
    "    hourly_data['hour_of_day'] = hourly_data['hour'].dt.hour\n",
    "\n",
    "    # Calculate the night-time and day-time usage duration for each air conditioner\n",
    "    night_usage = hourly_data[hourly_data['hour_of_day'].isin(night_hours)].groupby('ID')['Operational_status'].sum().reset_index()\n",
    "    night_usage.rename(columns={'Operational_status': 'night_usage'}, inplace=True)\n",
    "\n",
    "    day_usage = hourly_data[hourly_data['hour_of_day'].isin(day_hours)].groupby('ID')['Operational_status'].sum().reset_index()\n",
    "    day_usage.rename(columns={'Operational_status': 'day_usage'}, inplace=True)\n",
    "\n",
    "    # Summarize the total minutes of operation per air conditioner for each hour\n",
    "    hourly_usage = hourly_data.groupby(['ID', 'hour_of_day'])['Operational_status'].sum().unstack(fill_value=0)\n",
    "    hourly_usage.columns = [f'hour_{int(col)}_total_minutes' for col in hourly_usage.columns]\n",
    "\n",
    "    # Calculate the total operation minutes for 24 hours\n",
    "    hourly_usage['total_24h_minutes'] = hourly_usage.sum(axis=1)\n",
    "\n",
    "    # Calculate the hourly usage probability, i.e., the proportion of total operation minutes for each hour\n",
    "    hourly_usage_prob = hourly_usage.div(hourly_usage['total_24h_minutes'], axis=0)\n",
    "    hourly_usage_prob.drop(columns=['total_24h_minutes'], inplace=True)\n",
    "    hourly_usage_prob.columns = [f'hour_{int(col)}_prob' for col in range(24)]\n",
    "\n",
    "    # Calculate the average usage probability for day hours and night hours\n",
    "    hourly_usage_prob['day_avg_prob'] = hourly_usage_prob[[f'hour_{h}_prob' for h in day_hours]].mean(axis=1)\n",
    "    hourly_usage_prob['night_avg_prob'] = hourly_usage_prob[[f'hour_{h}_prob' for h in night_hours]].mean(axis=1)\n",
    "\n",
    "    # Merge night and day usage data, along with the hourly usage probabilities\n",
    "    summary = pd.merge(night_usage, day_usage, on='ID')\n",
    "    summary = pd.merge(summary, hourly_usage_prob, on='ID')\n",
    "\n",
    "    # Calculate the ratio of day usage to night usage\n",
    "    summary['day/night ratio'] = summary['day_usage'] / (summary['night_usage'] + 1e-10)\n",
    "    \n",
    "    # Calculate the ratio of day usage to total usage (day + night)\n",
    "    summary['day ratio'] = summary['day_usage'] / (summary['night_usage'] + summary['day_usage'] + 1e-10)\n",
    "    \n",
    "    # Calculate the ratio of night usage to total usage (day + night)\n",
    "    summary['night ratio'] = summary['night_usage'] / (summary['night_usage'] + summary['day_usage'] + 1e-10)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83687b5e-0f85-40a8-895a-c4c8b5d2f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterexample=process_ac_data(df_final) #example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee8ee2-14be-481a-bf11-d7238984a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"\n",
    "    Load the saved clustering models.\n",
    "    \n",
    "    Returns:\n",
    "    - kmeans_model: The primary clustering model.\n",
    "    - kmeans_recluster_model: The secondary clustering model.\n",
    "    \"\"\"\n",
    "    kmeans_model = joblib.load('kmeans_model.pkl')\n",
    "    kmeans_recluster_model = joblib.load('kmeans_recluster_model.pkl')\n",
    "    return kmeans_model, kmeans_recluster_model\n",
    "\n",
    "def predict_new_data(new_data, kmeans_model, kmeans_recluster_model):\n",
    "    \"\"\"\n",
    "    Make predictions on new data and perform secondary clustering.\n",
    "    \n",
    "    Parameters:\n",
    "    - new_data: The new data (a DataFrame containing hourly usage probabilities).\n",
    "    - kmeans_model: The pre-trained primary clustering model.\n",
    "    - kmeans_recluster_model: The pre-trained secondary clustering model.\n",
    "    \n",
    "    Returns:\n",
    "    - final_label: The final classification label (e.g., 'Bedroom', 'Livingroom', 'Mixedroom', 'work', 'nonwork').\n",
    "    \"\"\"\n",
    "    # Ensure new_data is a DataFrame and contains columns 'hour_0_prob' to 'hour_23_prob'\n",
    "    probability_features = [f'hour_{i}_prob' for i in range(24)]\n",
    "    \n",
    "    if not all(col in new_data.columns for col in probability_features):\n",
    "        raise ValueError(\"new_data DataFrame must contain columns: \" + \", \".join(probability_features))\n",
    "    \n",
    "    # Predict using the primary clustering model\n",
    "    cluster_label = kmeans_model.predict(new_data[probability_features])[0]\n",
    "    cluster_labels = {0: 'Bedroom', 1: 'Livingroom', 2: 'Mixedroom'}\n",
    "    cluster_name = cluster_labels[cluster_label]\n",
    "\n",
    "    # Perform secondary clustering based on the initial cluster result\n",
    "    if cluster_name == 'Livingroom':\n",
    "        recluster_label = kmeans_recluster_model.predict(new_data[probability_features])[0]\n",
    "        recluster_labels = {0: 'nonwork', 1: 'work'}\n",
    "    elif cluster_name == 'Mixedroom':\n",
    "        recluster_label = kmeans_recluster_model.predict(new_data[probability_features])[0]\n",
    "        recluster_labels = {0: 'work', 1: 'nonwork'}\n",
    "    else:\n",
    "        recluster_label = None\n",
    "        recluster_labels = None\n",
    "\n",
    "    # Generate the final label\n",
    "    final_label = f'{cluster_name} - {recluster_labels.get(recluster_label, \"\")}' if recluster_label is not None else cluster_name\n",
    "    return final_label\n",
    "\n",
    "# 1. Load the models\n",
    "kmeans_model, kmeans_recluster_model = load_models()\n",
    "\n",
    "# 2. Prepare the new data (replace `clusterexample` with the actual data you want to predict)\n",
    "# You can read this data from an Excel file or manually create a DataFrame\n",
    "new_data = clusterexample\n",
    "\n",
    "# 3. Make predictions on the new data\n",
    "final_label = predict_new_data(new_data, kmeans_model, kmeans_recluster_model)\n",
    "print(f'Predicted label for the new data: {final_label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478ba84-c6ab-4c26-b568-38ce81d4d3b7",
   "metadata": {},
   "source": [
    "## Comfort indoor air temperature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876e8f1-4421-4758-8dc0-d1053950e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mark stable and sleep periods\n",
    "def mark_stable_and_sleep_periods(df, state_col='Operational_status', temp_col='Setpoint', time_col='rawtime', \n",
    "                                  stable_col='Stable_period?', sleep_col='Sleep_period?'):\n",
    "    df[stable_col] = 0\n",
    "    df['Stable_period'] = (df[state_col] == 1) & (df[temp_col] == df[temp_col].shift(1))\n",
    "    df['Stable_period'] = df['Stable_period'].astype(int).cumsum() - df['Stable_period'].astype(int).cumsum().where(\n",
    "        ~df['Stable_period'].astype(bool)).ffill().fillna(0)\n",
    "    df[stable_col] = (df['Stable_period'] >= 15).astype(int)\n",
    "    df.drop(columns=['Stable_period'], inplace=True)\n",
    "    df[sleep_col] = 0\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df['hour_minute'] = df[time_col].dt.time\n",
    "    sleep_start = pd.to_datetime('22:00').time()\n",
    "    sleep_end = pd.to_datetime('08:00').time()\n",
    "    df[sleep_col] = df['hour_minute'].apply(lambda x: 1 if (x >= sleep_start or x < sleep_end) else 0)\n",
    "    df.drop(columns=['hour_minute'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Function to extract hourly averages during non-sleep periods\n",
    "def extract_and_average_stable_data(df, stable_col='Stable_period?', sleep_col='Sleep_period?', time_col='rawtime', \n",
    "                                    target_cols=None):\n",
    "    if target_cols is None:\n",
    "        target_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    stable_non_sleep_data = df[(df[stable_col] == 1) & (df[sleep_col] == 0)].copy()\n",
    "    stable_non_sleep_data[time_col] = pd.to_datetime(stable_non_sleep_data[time_col])\n",
    "    stable_non_sleep_data['hour'] = stable_non_sleep_data[time_col].dt.floor('H')\n",
    "    hourly_avg = stable_non_sleep_data.groupby('hour')[target_cols].mean().reset_index()\n",
    "    return hourly_avg\n",
    "\n",
    "# Function to extract hourly averages during sleep periods\n",
    "def extract_sleep_and_average_stable_data(df, state_col='Operational_status', sleep_col='Sleep_period?', \n",
    "                                          time_col='rawtime', target_cols=None):\n",
    "    if target_cols is None:\n",
    "        target_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    stable_sleep_data = df[(df[state_col] == 1) & (df[sleep_col] == 1)].copy()\n",
    "    stable_sleep_data[time_col] = pd.to_datetime(stable_sleep_data[time_col])\n",
    "    stable_sleep_data['hour'] = stable_sleep_data[time_col].dt.floor('H')\n",
    "    hourly_avg = stable_sleep_data.groupby('hour')[target_cols].mean().reset_index()\n",
    "    return hourly_avg\n",
    "\n",
    "# Function to perform linear regression and plot results\n",
    "def perform_linear_regression_and_plot(df, save_path, indoor_temp_col='Tin', outdoor_temp_col='Tout', device_id='ID'):\n",
    "    # Extract independent and dependent variables\n",
    "    X = df[outdoor_temp_col]\n",
    "    y = df[indoor_temp_col]\n",
    "    \n",
    "    # Add a constant for the intercept\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Perform linear regression\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    r_squared = model.rsquared\n",
    "    p_value = model.f_pvalue\n",
    "    \n",
    "    # Get regression coefficients\n",
    "    intercept = model.params['const']\n",
    "    slope = model.params[outdoor_temp_col]\n",
    "    equation = f\"y = {intercept:.4f} + {slope:.4f}*x\"\n",
    "    \n",
    "    # Create a results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'ID': [device_id],\n",
    "        'R²': [r_squared],\n",
    "        'p value': [p_value],\n",
    "        'regression equation': [equation]\n",
    "    })\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(df[outdoor_temp_col], df[indoor_temp_col], label='Data Points', color='#A4D9D7', alpha=0.5)\n",
    "    plt.plot(df[outdoor_temp_col], intercept + slope * df[outdoor_temp_col], color='#025F76', label='Regression Line')\n",
    "    \n",
    "    # Customize plot with Arial font and larger labels\n",
    "    plt.xlabel('Outdoor air temperature (°C)', fontsize=16, fontname='Arial')\n",
    "    plt.ylabel('Indoor air temperature (°C)', fontsize=16, fontname='Arial')\n",
    "    plt.xticks(fontsize=15, fontname='Arial')\n",
    "    plt.yticks(fontsize=15, fontname='Arial')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Display regression equation, R², and p-value on the plot\n",
    "    plt.text(\n",
    "        0.05, 0.95, \n",
    "        f\"Equation: {equation}\\nR² = {r_squared:.4f}\\nP-value = {p_value:.4e}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=12, \n",
    "        fontname='Arial', \n",
    "        verticalalignment='top',\n",
    "        bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8)\n",
    "    )\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='png', dpi=400)\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    plt.show()        \n",
    "    return results_df\n",
    "\n",
    "# Main processing function\n",
    "def process_device_data_from_df(device_id, room_type, df, output_folder, \n",
    "                                time_col='rawtime', state_col='Operational_status', \n",
    "                                temp_col='Setpoint', sleep_col='Sleep_period?', stable_col='Stable_period?',\n",
    "                                indoor_temp_col='Tin', outdoor_temp_col='Tout'):\n",
    "    # Step 1: Mark stable and sleep periods\n",
    "    df = mark_stable_and_sleep_periods(df, state_col=state_col, temp_col=temp_col, time_col=time_col,\n",
    "                                       stable_col=stable_col, sleep_col=sleep_col)\n",
    "\n",
    "    # Step 2: Process based on room type\n",
    "    if room_type == 'Bedroom':\n",
    "        print(f\"Processing Bedroom data for ID {device_id}...\")\n",
    "        hourly_avg_sleep = extract_sleep_and_average_stable_data(df, state_col=state_col, sleep_col=sleep_col, \n",
    "                                                                time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        output_file = os.path.join(output_folder, f\"{device_id}_sleep_hourly_average.xlsx\")\n",
    "        hourly_avg_sleep.to_excel(output_file, index=False)\n",
    "\n",
    "    elif 'Livingroom' in room_type:\n",
    "        print(f\"Processing Livingroom data for ID {device_id}...\")\n",
    "        hourly_avg = extract_and_average_stable_data(df, stable_col=stable_col, sleep_col=sleep_col, \n",
    "                                                     time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        hourly_avg_file = os.path.join(output_folder, f\"{device_id}_wake_hourly_average.xlsx\")\n",
    "        hourly_avg.to_excel(hourly_avg_file, index=False)\n",
    "        \n",
    "        # Create save path for the regression plot\n",
    "        save_path = os.path.join(output_folder, f\"{device_id}_regression_plot.png\")\n",
    "        regression_results = perform_linear_regression_and_plot(hourly_avg, indoor_temp_col=indoor_temp_col, \n",
    "                                           outdoor_temp_col=outdoor_temp_col, device_id=device_id, \n",
    "                                           save_path=save_path)\n",
    "        # Save regression results as Excel\n",
    "        regression_results_file = os.path.join(output_folder, f\"{device_id}_regression_results.xlsx\")\n",
    "        regression_results.to_excel(regression_results_file, index=False)\n",
    "\n",
    "    elif 'Mixedroom' in room_type:\n",
    "        print(f\"Processing Mixedroom data for ID {device_id}...\")\n",
    "        # Non-sleep data processing\n",
    "        hourly_avg = extract_and_average_stable_data(df, stable_col=stable_col, sleep_col=sleep_col, \n",
    "                                                     time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        hourly_avg_file = os.path.join(output_folder, f\"{device_id}_wake_hourly_average.xlsx\")\n",
    "        hourly_avg.to_excel(hourly_avg_file, index=False)\n",
    "        \n",
    "        # Create save path for the regression plot\n",
    "        save_path = os.path.join(output_folder, f\"{device_id}_regression_plot.png\")\n",
    "        regression_results = perform_linear_regression_and_plot(hourly_avg, indoor_temp_col=indoor_temp_col, \n",
    "                                           outdoor_temp_col=outdoor_temp_col, device_id=device_id, \n",
    "                                           save_path=save_path)\n",
    "        # Save regression results as Excel\n",
    "        regression_results_file = os.path.join(output_folder, f\"{device_id}_regression_results.xlsx\")\n",
    "        regression_results.to_excel(regression_results_file, index=False)\n",
    "        \n",
    "        # Sleep data processing\n",
    "        hourly_avg_sleep = extract_sleep_and_average_stable_data(df, state_col=state_col, sleep_col=sleep_col, \n",
    "                                                                time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        sleep_avg_file = os.path.join(output_folder, f\"{device_id}_sleep_hourly_average.xlsx\")\n",
    "        hourly_avg_sleep.to_excel(sleep_avg_file, index=False)\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown room type for ID {device_id}. Skipping...\")\n",
    "\n",
    "# Example usage\n",
    "room_type = 'Mixedroom+work'  # Predicted room type from your model\n",
    "process_device_data_from_df(\n",
    "    device_id='83562883812609_example',\n",
    "    room_type=room_type,\n",
    "    df=df_final,\n",
    "    output_folder='example/output'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63afa9b-fc84-4f84-8a6e-cb7c37cc7a9c",
   "metadata": {},
   "source": [
    "## Comfort indoor air temperature setting schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45504abc-b599-48ee-b646-82f30b42d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_schedule_generate(df, weather_data_df):\n",
    "    df['hour'] = pd.to_datetime(df['hour'])\n",
    "    df['hour_str'] = df['hour'].dt.hour.astype(str)\n",
    "    full_hours = [str(i) for i in range(24)]\n",
    "    night_hours = ['22', '23', '0', '1', '2', '3', '4', '5', '6', '7']\n",
    "    filtered_df = df[df['hour_str'].isin(night_hours)]\n",
    "    avg_temp_by_hour = filtered_df.groupby('hour_str')['Tin'].mean()\n",
    "    avg_temp_by_hour = avg_temp_by_hour.reindex(full_hours).fillna(method='ffill').fillna(method='bfill')\n",
    "    night_data_expanded_list = []\n",
    "    for month in weather_data_df['Month'].unique():\n",
    "        for day in weather_data_df[weather_data_df['Month'] == month]['Day'].unique():\n",
    "            for hour_str in night_hours:\n",
    "                hour = int(hour_str)\n",
    "                temperature = avg_temp_by_hour.get(hour_str, np.nan)\n",
    "                night_data_expanded_list.append({\n",
    "                    'Month': month,\n",
    "                    'Day': day,\n",
    "                    'Hour': hour,\n",
    "                    'Comfort_Temperature': round(temperature, 1),\n",
    "                    'operational_status': 'on',\n",
    "                    'room_type': ' '\n",
    "                })\n",
    "    night_data_expanded = pd.DataFrame(night_data_expanded_list)\n",
    "    daytime_data_list = []\n",
    "    for month in weather_data_df['Month'].unique():\n",
    "        for day in weather_data_df[weather_data_df['Month'] == month]['Day'].unique():\n",
    "            for hour in range(8, 22):\n",
    "                daytime_data_list.append({\n",
    "                    'Month': month,\n",
    "                    'Day': day,\n",
    "                    'Hour': hour,\n",
    "                    'Comfort_Temperature': np.nan,\n",
    "                    'operational_status': 'off',\n",
    "                    'room_type': ' '\n",
    "                })\n",
    "    daytime_data = pd.DataFrame(daytime_data_list)\n",
    "    result_df = pd.concat([night_data_expanded, daytime_data], ignore_index=True)\n",
    "    result_df = result_df.sort_values(by=['Month', 'Day', 'Hour']).reset_index(drop=True)\n",
    "    return result_df\n",
    "\n",
    "# Function to process Bedroom schedules\n",
    "def process_sleep_schedules(\n",
    "    weather_data_file,\n",
    "    raw_data_file,\n",
    "    output_folder_path,\n",
    "    room_type\n",
    "):\n",
    "    night_data_df = pd.read_excel(raw_data_file)\n",
    "    weather_data_df = pd.read_excel(weather_data_file)\n",
    "    comfort_df_night = sleep_schedule_generate(night_data_df, weather_data_df)\n",
    "    \n",
    "    # For periods outside the sleep schedule, set operational status to 'off' and Comfort_Temperature to NaN\n",
    "    comfort_df_night['operational_status'] = comfort_df_night.apply(\n",
    "        lambda row: 'on' if pd.notna(row['Comfort_Temperature']) else 'off', axis=1\n",
    "    )\n",
    "    \n",
    "    # Add the room type information for Bedroom\n",
    "    comfort_df_night['room_type'] = 'Bedroom+nonwork'\n",
    "\n",
    "    # Drop unnecessary columns if they exist and keep only the necessary columns\n",
    "    columns_to_keep = ['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']\n",
    "    comfort_df_night = comfort_df_night[columns_to_keep]\n",
    "    \n",
    "    # Save the resulting DataFrame to an Excel file\n",
    "    output_file_path = os.path.join(output_folder_path, f\"comfort_temperature_{room_type}.xlsx\")\n",
    "    try:\n",
    "        comfort_df_night.to_excel(output_file_path, index=False)\n",
    "        print(f\"Saved combined comfort temperature data to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comfort temperature data: {e}\")\n",
    "\n",
    "\n",
    "# Function to process comfort for Livingroom Work\n",
    "def process_work_living_room_comfort(regression_file, weather_data_file, output_folder_path, room_type):\n",
    "\n",
    "    try:\n",
    "        regression_df = pd.read_excel(regression_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading regression file {regression_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        weather_data_df = pd.read_excel(weather_data_file)\n",
    "        hourly_temperatures = weather_data_df['Dry']\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data file {weather_data_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Extract the device ID from the raw data file path (e.g., \"83562883812609 example\")\n",
    "    device_id = os.path.basename(raw_data_file).split('_')[0].strip()\n",
    "\n",
    "    # Ensure device_id is treated as a string and remove extra spaces\n",
    "    device_id = str(device_id).strip()\n",
    "\n",
    "    # Match the device ID in the regression file\n",
    "    regression_row = regression_df[regression_df['ID'].astype(str).str.strip() == device_id]\n",
    "\n",
    "    if regression_row.empty:\n",
    "        print(f\"No regression equation found for {device_id}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    regression_equation = regression_row['regression equation'].values[0].strip()  # Strip any leading/trailing spaces\n",
    "\n",
    "    # Use regex to extract intercept and slope from the regression equation\n",
    "    match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "    if not match:\n",
    "        print(f\"Invalid regression equation format for {device_id}: {regression_equation}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    intercept = float(match.group(1))\n",
    "    slope = float(match.group(2))\n",
    "\n",
    "    comfort_temperatures = (intercept + slope * hourly_temperatures).round(1)\n",
    "\n",
    "    weather_data_df['Comfort_Temperature'] = comfort_temperatures\n",
    "    weather_data_df['operational_status'] = np.where(\n",
    "        weather_data_df['Hour'].isin([13, 14, 19, 20, 21, 22]), \n",
    "        'on', \n",
    "        'off'\n",
    "    )\n",
    "    weather_data_df['room_type'] = f'{room_type}'\n",
    "\n",
    "    weather_data_df.loc[weather_data_df['operational_status'] == 'off', 'Comfort_Temperature'] = np.nan\n",
    "\n",
    "    comfort_df = weather_data_df[['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']]\n",
    "\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    output_file_path = os.path.join(output_folder_path, f\"comfort_temperature_{room_type}.xlsx\")\n",
    "    try:\n",
    "        comfort_df.to_excel(output_file_path, index=False)\n",
    "        print(f\"Saved comfort temperature data for {device_id} to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comfort temperature data for {device_id}: {e}\")\n",
    "        \n",
    "        \n",
    "# Function to process comfort for Livingroom nonwork\n",
    "def process_nonwork_living_room_comfort(regression_file, weather_data_file, output_folder_path, room_type):\n",
    "    try:\n",
    "        regression_df = pd.read_excel(regression_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading regression file {regression_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        weather_data_df = pd.read_excel(weather_data_file)\n",
    "        hourly_temperatures = weather_data_df['Dry']\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data file {weather_data_file}: {e}\")\n",
    "        return\n",
    "    \n",
    "    device_id = os.path.basename(raw_data_file).split('_')[0].strip()\n",
    "\n",
    "    device_id = str(device_id).strip()\n",
    "    regression_row = regression_df[regression_df['ID'].astype(str).str.strip() == device_id]\n",
    "    if regression_row.empty:\n",
    "        print(f\"No regression equation found for {device_id}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    regression_equation = regression_row['regression equation'].values[0].strip()\n",
    "\n",
    "    # Use regex to extract intercept and slope from the regression equation\n",
    "    match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "    if not match:\n",
    "        print(f\"Invalid regression equation format for {device_id}: {regression_equation}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    intercept = float(match.group(1))\n",
    "    slope = float(match.group(2))\n",
    "\n",
    "    comfort_temperatures = (intercept + slope * hourly_temperatures).round(1)\n",
    "\n",
    "    weather_data_df['Comfort_Temperature'] = comfort_temperatures\n",
    "    weather_data_df['operational_status'] = np.where(\n",
    "        weather_data_df['Hour'].isin([9, 10, 11, 12, 13,14,15,16, 17, 18, 19, 20, 21, 22]), \n",
    "        'on', \n",
    "        'off'\n",
    "    )\n",
    "    weather_data_df['room_type'] = f'{room_type}'\n",
    "\n",
    "    weather_data_df.loc[weather_data_df['operational_status'] == 'off', 'Comfort_Temperature'] = np.nan\n",
    "\n",
    "    comfort_df = weather_data_df[['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']]\n",
    "\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "    output_file_path = os.path.join(output_folder_path, f\"comfort_temperature_{room_type}.xlsx\")\n",
    "    try:\n",
    "        comfort_df.to_excel(output_file_path, index=False)\n",
    "        print(f\"Saved comfort temperature data for {device_id} to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comfort temperature data for {device_id}: {e}\")        \n",
    "        \n",
    "# Function to handle Mixedroom comfort\n",
    "def process_mixed_non_work_room_comfort(\n",
    "    regression_file,\n",
    "    weather_data_file,\n",
    "    raw_data_file,\n",
    "    output_folder_path,\n",
    "    room_type\n",
    "):\n",
    "\n",
    "    # Step 2: Read the regression equation.\n",
    "    regression_df = pd.read_excel(regression_file)\n",
    "    regression_df['ID'] = regression_df['ID'].astype(str).str.replace('.0', '', regex=False).str.strip()\n",
    "\n",
    "    regression_equation = regression_df['regression equation'].values[0]\n",
    "    \n",
    "    # Step 3: Parse the regression equation to extract coefficients.\n",
    "    match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "    if not match:\n",
    "        print(f\"Invalid regression equation format: {regression_equation}\")\n",
    "        return\n",
    "\n",
    "    intercept = float(match.group(1))\n",
    "    slope = float(match.group(2))\n",
    "    \n",
    "    # Step 4: Read the hourly outdoor temperature data from May to October.\n",
    "    weather_data_df = pd.read_excel(weather_data_file)\n",
    "    hourly_temperatures = weather_data_df['Dry']  # Use 'Dry' as the outdoor temperature.\n",
    "\n",
    "    # Step 4: Calculate comfort temperature for selected daytime hours (8:00 - 21:00).\n",
    "    daytime_hours = [8,9,10,11,12, 13,14,15,16,17, 18, 19, 20, 21]\n",
    "    comfort_temperatures_day = intercept + slope * hourly_temperatures\n",
    "    comfort_df_day = weather_data_df[weather_data_df['Hour'].isin(daytime_hours)].copy()\n",
    "    comfort_df_day['Comfort_Temperature'] = comfort_temperatures_day.round(1)\n",
    "    comfort_df_day['operational_status'] = 'on'\n",
    "    \n",
    "    # For other daytime hours (08:00 - 10:00, 14:00 - 16:00), set operational status to 'off' and temperature to NaN.\n",
    "    other_daytime_hours = [h for h in range(8, 22) if h not in daytime_hours]\n",
    "    other_df_day = weather_data_df[weather_data_df['Hour'].isin(other_daytime_hours)].copy()\n",
    "    other_df_day['Comfort_Temperature'] = np.nan\n",
    "    other_df_day['operational_status'] = 'off'\n",
    "    \n",
    "    # Combine both day on and off hours.\n",
    "    comfort_df_day = pd.concat([comfort_df_day, other_df_day], ignore_index=True)\n",
    "\n",
    "    # Step 5: Process night-time temperatures (22:00 - 7:00) using sleep schedule.\n",
    "    night_data_df = pd.read_excel(raw_data_file)\n",
    "    comfort_df_night = sleep_schedule_generate(night_data_df, weather_data_df)\n",
    "\n",
    "    # Step 6: Merge day and expanded night data into a single DataFrame.\n",
    "    comfort_df = pd.concat([comfort_df_day, comfort_df_night], ignore_index=True)\n",
    "    comfort_df['room_type'] = 'Mixedroom+nonwork'\n",
    "    comfort_df = comfort_df.drop_duplicates(subset=['Month', 'Day', 'Hour']).sort_values(by=['Month', 'Day', 'Hour']).reset_index(drop=True)\n",
    "\n",
    "    # Step 7: Drop unnecessary columns if they exist and keep only the necessary columns.\n",
    "    columns_to_keep = ['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']\n",
    "    comfort_df = comfort_df[columns_to_keep]\n",
    "\n",
    "    # Step 8: Save the resulting DataFrame to an Excel file.\n",
    "    output_file_path = os.path.join(output_folder_path, f\"comfort_temperature_{room_type}.xlsx\")\n",
    "    try:\n",
    "        comfort_df.to_excel(output_file_path, index=False)\n",
    "        print(f\"Saved combined comfort temperature data to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comfort temperature data: {e}\")\n",
    "\n",
    "\n",
    "def process_mixed_work_room_comfort(\n",
    "    regression_file,\n",
    "    weather_data_file,\n",
    "    raw_data_file,\n",
    "    output_folder_path,\n",
    "    room_type\n",
    "):\n",
    "\n",
    "    # Step 2: Read the regression equation.\n",
    "    regression_df = pd.read_excel(regression_file)\n",
    "    regression_df['ID'] = regression_df['ID'].astype(str).str.replace('.0', '', regex=False).str.strip()\n",
    "\n",
    "    regression_equation = regression_df['regression equation'].values[0]\n",
    "    \n",
    "    # Step 3: Parse the regression equation to extract coefficients.\n",
    "    match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "    if not match:\n",
    "        print(f\"Invalid regression equation format: {regression_equation}\")\n",
    "        return\n",
    "\n",
    "    intercept = float(match.group(1))\n",
    "    slope = float(match.group(2))\n",
    "    \n",
    "    # Step 4: Read the hourly outdoor temperature data from May to October.\n",
    "    weather_data_df = pd.read_excel(weather_data_file)\n",
    "    hourly_temperatures = weather_data_df['Dry']  # Use 'Dry' as the outdoor temperature.\n",
    "\n",
    "    # Step 4: Calculate comfort temperature for selected daytime hours (11:00 - 13:00 and 17:00 - 21:00).\n",
    "    daytime_hours = [12, 13, 18, 19, 20, 21]\n",
    "    comfort_temperatures_day = intercept + slope * hourly_temperatures\n",
    "    comfort_df_day = weather_data_df[weather_data_df['Hour'].isin(daytime_hours)].copy()\n",
    "    comfort_df_day['Comfort_Temperature'] = comfort_temperatures_day.round(1)\n",
    "    comfort_df_day['operational_status'] = 'on'\n",
    "    \n",
    "    # For other daytime hours (08:00 - 10:00, 14:00 - 16:00), set operational status to 'off' and temperature to NaN.\n",
    "    other_daytime_hours = [h for h in range(8, 22) if h not in daytime_hours]\n",
    "    other_df_day = weather_data_df[weather_data_df['Hour'].isin(other_daytime_hours)].copy()\n",
    "    other_df_day['Comfort_Temperature'] = np.nan\n",
    "    other_df_day['operational_status'] = 'off'\n",
    "    \n",
    "    # Combine both day on and off hours.\n",
    "    comfort_df_day = pd.concat([comfort_df_day, other_df_day], ignore_index=True)\n",
    "\n",
    "    # Step 5: Process night-time temperatures (22:00 - 7:00) using sleep schedule.\n",
    "    night_data_df = pd.read_excel(raw_data_file)\n",
    "    comfort_df_night = sleep_schedule_generate(night_data_df, weather_data_df)\n",
    "\n",
    "    # Step 6: Merge day and expanded night data into a single DataFrame.\n",
    "    comfort_df = pd.concat([comfort_df_day, comfort_df_night], ignore_index=True)\n",
    "    comfort_df['room_type'] = 'Mixedroom+non-work'\n",
    "    comfort_df = comfort_df.drop_duplicates(subset=['Month', 'Day', 'Hour']).sort_values(by=['Month', 'Day', 'Hour']).reset_index(drop=True)\n",
    "\n",
    "    # Step 7: Drop unnecessary columns if they exist and keep only the necessary columns.\n",
    "    columns_to_keep = ['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']\n",
    "    comfort_df = comfort_df[columns_to_keep]\n",
    "\n",
    "    # Step 8: Save the resulting DataFrame to an Excel file.\n",
    "    output_file_path = os.path.join(output_folder_path, f\"comfort_temperature_{room_type}.xlsx\")\n",
    "    try:\n",
    "        comfort_df.to_excel(output_file_path, index=False)\n",
    "        print(f\"Saved combined comfort temperature data to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comfort temperature data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275559b5-28b6-4065-b20f-eb053bd3e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_room_schedules(\n",
    "    room_type,\n",
    "    regression_file,\n",
    "    weather_data_file,\n",
    "    raw_data_file,\n",
    "    output_folder_path\n",
    "):\n",
    "    if room_type == 'Bedroom':\n",
    "        process_sleep_schedules(\n",
    "            weather_data_file=weather_data_file,\n",
    "            raw_data_file=raw_data_file,\n",
    "            output_folder_path=output_folder_path,\n",
    "            room_type =room_type \n",
    "        )\n",
    "    elif room_type == 'Livingroom+work':\n",
    "        process_work_living_room_comfort(\n",
    "            regression_file=regression_file,\n",
    "            weather_data_file=weather_data_file,\n",
    "            output_folder_path=output_folder_path,\n",
    "            room_type=room_type  \n",
    "        )\n",
    "    elif room_type == 'Livingroom+non-work':\n",
    "        process_nonwork_living_room_comfort(\n",
    "            regression_file=regression_file,\n",
    "            weather_data_file=weather_data_file,\n",
    "            output_folder_path=output_folder_path,\n",
    "            room_type =room_type \n",
    "        )\n",
    "    elif room_type == 'Mixedroom+non-work':\n",
    "        process_mixed_non_work_room_comfort(\n",
    "            regression_file=regression_file,\n",
    "            weather_data_file=weather_data_file,\n",
    "            raw_data_file=raw_data_file,\n",
    "            output_folder_path=output_folder_path,\n",
    "            room_type =room_type \n",
    "        )\n",
    "    elif room_type == 'Mixedroom+work':\n",
    "        process_mixed_work_room_comfort(\n",
    "            regression_file=regression_file,\n",
    "            weather_data_file=weather_data_file,\n",
    "            raw_data_file=raw_data_file,\n",
    "            output_folder_path=output_folder_path,\n",
    "            room_type =room_type \n",
    "        )\n",
    "    else:\n",
    "        print(f\"Invalid room type: {room_type}. Please choose from 'Bedroom', 'Livingroom+work', 'Livingroom+non-work', 'Mixedroom+work', or 'Mixedroom+non-work'.\")\n",
    "\n",
    "raw_data_file = 'example/output/83562883812609_example_sleep_hourly_average.xlsx'\n",
    "regression_file = 'example/output/83562883812609_example_regression_results.xlsx'\n",
    "weather_data_file = 'example/weatherdata.xlsx'\n",
    "output_folder_path = 'example/output/schedule'\n",
    "room_type = 'Livingroom+work'\n",
    "\n",
    "generate_room_schedules(\n",
    "    room_type,\n",
    "    regression_file,\n",
    "    weather_data_file,\n",
    "    raw_data_file,\n",
    "    output_folder_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de5b37-f32f-4924-8009-e50b15e05c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14a28c-22db-4c6a-8e51-96f796914063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
