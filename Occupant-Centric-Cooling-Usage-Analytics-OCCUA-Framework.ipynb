{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ef872-f024-44a2-a5f3-2e4859a0ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1c173-ecc8-418e-bbed-58d10bd7e73c",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5d358-5904-422c-9cd7-43ecde808ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_dataframe(file_path):\n",
    "    # Step 1: Read the Excel file\n",
    "    df_cleaned = pd.read_excel(file_path)\n",
    "\n",
    "    # Step 3: Fill missing values based on time\n",
    "    def fill_missing_values_based_on_time(dataframe):\n",
    "        dataframe['rawtime'] = pd.to_datetime(dataframe['rawtime'])\n",
    "        for index, row in dataframe.iterrows():\n",
    "            if row.isnull().any():\n",
    "                prev_row = dataframe.iloc[index - 1] if index - 1 >= 0 else None\n",
    "                next_row = dataframe.iloc[index + 1] if index + 1 < len(dataframe) else None\n",
    "                for col in dataframe.columns:\n",
    "                    if pd.isnull(row[col]):\n",
    "                        if prev_row is not None and next_row is not None:\n",
    "                            prev_diff = abs(row['rawtime'] - prev_row['rawtime'])\n",
    "                            next_diff = abs(row['rawtime'] - next_row['rawtime'])\n",
    "                            if prev_diff < next_diff:\n",
    "                                dataframe.at[index, col] = prev_row[col]\n",
    "                            else:\n",
    "                                dataframe.at[index, col] = next_row[col]\n",
    "                        elif prev_row is not None:\n",
    "                            dataframe.at[index, col] = prev_row[col]\n",
    "                        elif next_row is not None:\n",
    "                            dataframe.at[index, col] = next_row[col]\n",
    "        return dataframe\n",
    "\n",
    "    df_filled = fill_missing_values_based_on_time(df_cleaned)\n",
    "\n",
    "    # Step 4: Convert rawtime to \"YYYY-MM-DD HH:MM\" format\n",
    "    df_filled['rawtime'] = df_filled['rawtime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "    # Step 5: Check for duplicate timestamps\n",
    "    def check_duplicate_timestamps(dataframe):\n",
    "        duplicate_counts = dataframe['rawtime'].value_counts()\n",
    "        duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "        if not duplicates.empty:\n",
    "            print(f\"There are {duplicates.sum()} duplicate timestamps. The first duplicate value will be removed.\")\n",
    "        return duplicates\n",
    "\n",
    "    duplicates_info = check_duplicate_timestamps(df_filled)\n",
    "\n",
    "    # Step 6: Remove the first occurrence of duplicate timestamps\n",
    "    def remove_first_duplicate_and_recheck(dataframe):\n",
    "        duplicate_timestamps = dataframe['rawtime'][dataframe['rawtime'].duplicated(keep='first')]\n",
    "        dataframe_cleaned = dataframe.drop(duplicate_timestamps.index)\n",
    "        duplicate_counts = dataframe_cleaned['rawtime'].value_counts()\n",
    "        duplicates_after_removal = duplicate_counts[duplicate_counts > 1]\n",
    "        if duplicates_after_removal.empty:\n",
    "            print(\"Processing complete, no duplicate timestamps remain.\")\n",
    "        else:\n",
    "            print(f\"There are still {duplicates_after_removal.sum()} duplicate timestamps remaining.\")\n",
    "        return dataframe_cleaned\n",
    "\n",
    "    df_cleaned_final = remove_first_duplicate_and_recheck(df_filled)\n",
    "\n",
    "    # Step 7: Insert missing rows with ID as the first column\n",
    "    def insert_missing_rows_with_id_first(dataframe):\n",
    "        dataframe['rawtime'] = pd.to_datetime(dataframe['rawtime'])\n",
    "        full_time_range = pd.date_range(start=dataframe['rawtime'].min(), end=dataframe['rawtime'].max(), freq='T')\n",
    "        df_full = pd.DataFrame({'rawtime': full_time_range})\n",
    "        df_merged = pd.merge(df_full, dataframe, on='rawtime', how='left')\n",
    "        df_merged['ID'] = dataframe['ID'].iloc[0]\n",
    "        df_merged['rawtime'] = df_merged['rawtime'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "        columns_order = ['ID', 'rawtime'] + [col for col in df_merged.columns if col not in ['ID', 'rawtime']]\n",
    "        return df_merged[columns_order]\n",
    "\n",
    "    df_with_inserted_rows = insert_missing_rows_with_id_first(df_cleaned_final)\n",
    "\n",
    "    # Step 8: Fill the 'Operational_status' column with the previous value\n",
    "    def fill_previous_value_for_column(dataframe, column_name):\n",
    "        dataframe[column_name] = dataframe[column_name].fillna(method='ffill')\n",
    "        return dataframe\n",
    "\n",
    "    df_filled_with_previous = fill_previous_value_for_column(df_with_inserted_rows, 'Operational_status')\n",
    "\n",
    "    # Step 9: Interpolate 'Tin' and 'Tout' and round to 1 decimal place\n",
    "    def fill_with_interpolation_and_rounding(dataframe, columns, decimal_places=1):\n",
    "        dataframe[columns] = dataframe[columns].interpolate(method='linear', limit_direction='both').round(decimal_places)\n",
    "        return dataframe\n",
    "\n",
    "    df_filled_with_rounded_interpolation = fill_with_interpolation_and_rounding(df_filled_with_previous, ['Tin', 'Tout'], decimal_places=1)\n",
    "\n",
    "    # Step 10: Fill 'Setpoint' column with the previous value\n",
    "    df_filled_with_final_adjustments = fill_previous_value_for_column(df_filled_with_rounded_interpolation, 'Setpoint')\n",
    "\n",
    "    # Step 11: Function to count the number of shutdown cycles\n",
    "    def count_shutdown_cycles(dataframe, column_name):\n",
    "        shutdown_cycles = 0\n",
    "        in_shutdown = False\n",
    "    \n",
    "        for i in range(len(dataframe)):\n",
    "            current_status = dataframe.iloc[i][column_name]\n",
    "            if current_status == 0 and not in_shutdown:\n",
    "                in_shutdown = True  # Start of a shutdown cycle\n",
    "            elif current_status == 1 and in_shutdown:\n",
    "                shutdown_cycles += 1  # End of a shutdown cycle\n",
    "                in_shutdown = False  # Reset for the next cycle   \n",
    "        return shutdown_cycles\n",
    "    # Apply the function to count shutdown cycles in 'Operational_status'\n",
    "    shutdown_cycles_count = count_shutdown_cycles(df_filled_with_final_adjustments, 'Operational_status')\n",
    "    \n",
    "    # Display the result\n",
    "    print(f\"There are {shutdown_cycles_count} shutdown cycles.\")\n",
    "\n",
    "    # Step 12: Function to replace temperature values with 'no_records' for each shutdown cycle\n",
    "    def replace_temperatures_in_shutdown_cycles(dataframe, column_name, temperature_columns):\n",
    "        in_shutdown = False\n",
    "        shutdown_start = None\n",
    "    \n",
    "        for i in range(len(dataframe)):\n",
    "            current_status = dataframe.iloc[i][column_name]\n",
    "        \n",
    "            if current_status == 0 and not in_shutdown:\n",
    "                # Mark the start of the shutdown cycle\n",
    "                in_shutdown = True\n",
    "                shutdown_start = i\n",
    "            elif current_status == 1 and in_shutdown:\n",
    "                # End of the shutdown cycle, process the rows\n",
    "                if shutdown_start is not None and (i - shutdown_start) > 1:\n",
    "                    # Replace values from the second 'Operational_status' == 0 until the last one\n",
    "                    dataframe.loc[shutdown_start + 1:i - 1, temperature_columns] = 'no_records'\n",
    "                # Reset for the next cycle\n",
    "                in_shutdown = False\n",
    "                shutdown_start = None\n",
    "\n",
    "        return dataframe\n",
    "    temperature_columns_to_replace = ['Setpoint', 'Tin', 'Tout']\n",
    "    df_replaced_temperatures = replace_temperatures_in_shutdown_cycles(df_filled_with_final_adjustments, 'Operational_status', temperature_columns_to_replace)\n",
    "\n",
    "    # Step 13: Add the \"On/Off action\" column\n",
    "    def add_switch_action_column(dataframe, status_column):\n",
    "        dataframe['On/OFF'] = ''\n",
    "        for i in range(len(dataframe) - 1):\n",
    "            current_status = dataframe.iloc[i][status_column]\n",
    "            next_status = dataframe.iloc[i + 1][status_column]\n",
    "            if current_status == 0 and next_status == 1:\n",
    "                dataframe.at[i + 1, 'On/OFF'] = 'ON'\n",
    "            elif current_status == 1 and next_status == 0:\n",
    "                dataframe.at[i + 1, 'On/OFF'] = 'OFF'\n",
    "        return dataframe\n",
    "\n",
    "    df_with_switch_action = add_switch_action_column(df_replaced_temperatures, 'Operational_status')\n",
    "\n",
    "    # Step 14: Add the \"Setpoint adjustment\" column\n",
    "    def add_temperature_action_column_with_handling(dataframe, temp_column):\n",
    "        dataframe['Setpoint adjustment'] = ''\n",
    "        for i in range(len(dataframe) - 1):\n",
    "            current_temp = dataframe.iloc[i][temp_column]\n",
    "            next_temp = dataframe.iloc[i + 1][temp_column]\n",
    "            if pd.api.types.is_numeric_dtype(type(current_temp)) and pd.api.types.is_numeric_dtype(type(next_temp)):\n",
    "                if next_temp > current_temp:\n",
    "                    dataframe.at[i + 1, 'Setpoint adjustment'] = 'Upper'\n",
    "                elif next_temp < current_temp:\n",
    "                    dataframe.at[i + 1, 'Setpoint adjustment'] = 'Lower'\n",
    "        return dataframe\n",
    "\n",
    "    df_final = add_temperature_action_column_with_handling(df_with_switch_action, 'Setpoint')\n",
    "\n",
    "    # Step 15: Display the final dataframe\n",
    "    display(df_final)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478ba84-c6ab-4c26-b568-38ce81d4d3b7",
   "metadata": {},
   "source": [
    "## Comfort indoor air temperature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d5234-f281-467c-9661-c156e3af5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to mark stable and sleep periods\n",
    "def mark_stable_and_sleep_periods(df, state_col='Operational_status', temp_col='Setpoint', time_col='rawtime', \n",
    "                                  stable_col='Stable_period', sleep_col='Sleep_period'):\n",
    "    df[stable_col] = 0\n",
    "    df['Stable_period'] = (df[state_col] == 1) & (df[temp_col] == df[temp_col].shift(1))\n",
    "    df['Stable_period'] = df['Stable_period'].astype(int).cumsum() - df['Stable_period'].astype(int).cumsum().where(\n",
    "        ~df['Stable_period'].astype(bool)).ffill().fillna(0)\n",
    "    df[stable_col] = (df['Stable_period'] >= 15).astype(int)\n",
    "    df.drop(columns=['Stable_period'], inplace=True)\n",
    "    df[sleep_col] = 0\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df['hour_minute'] = df[time_col].dt.time\n",
    "    sleep_start = pd.to_datetime('22:00').time()\n",
    "    sleep_end = pd.to_datetime('08:00').time()\n",
    "    df[sleep_col] = df['hour_minute'].apply(lambda x: 1 if (x >= sleep_start or x < sleep_end) else 0)\n",
    "    df.drop(columns=['hour_minute'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Function to extract hourly averages during non-sleep periods\n",
    "def extract_and_average_stable_data(df, stable_col='Stable_period', sleep_col='Sleep_period', time_col='rawtime', \n",
    "                                    target_cols=None):\n",
    "    if target_cols is None:\n",
    "        target_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    stable_non_sleep_data = df[(df[stable_col] == 1) & (df[sleep_col] == 0)].copy()\n",
    "    stable_non_sleep_data[time_col] = pd.to_datetime(stable_non_sleep_data[time_col])\n",
    "    stable_non_sleep_data['hour'] = stable_non_sleep_data[time_col].dt.floor('H')\n",
    "    hourly_avg = stable_non_sleep_data.groupby('hour')[target_cols].mean().reset_index()\n",
    "    return hourly_avg\n",
    "\n",
    "# Function to extract hourly averages during sleep periods\n",
    "def sleepextract_and_average_stable_data(df, state_col='Operational_status', sleep_col='Sleep_period', \n",
    "                                         time_col='rawtime', target_cols=None):\n",
    "    if target_cols is None:\n",
    "        target_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    stable_sleep_data = df[(df[state_col] == 1) & (df[sleep_col] == 1)].copy()\n",
    "    stable_sleep_data[time_col] = pd.to_datetime(stable_sleep_data[time_col])\n",
    "    stable_sleep_data['hour'] = stable_sleep_data[time_col].dt.floor('H')\n",
    "    hourly_avg = stable_sleep_data.groupby('hour')[target_cols].mean().reset_index()\n",
    "    return hourly_avg\n",
    "\n",
    "# Function to perform linear regression and plot results\n",
    "def perform_linear_regression_and_plot(df, save_path, indoor_temp_col='室内温度', outdoor_temp_col='室外温度', device_id='设备ID'):\n",
    "    \"\"\"\n",
    "    Perform linear regression and plot results for wake state with specified formatting.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Dataframe containing data for regression.\n",
    "    - save_path (str): Path to save the regression plot as a PNG file.\n",
    "    - indoor_temp_col (str): Column name for indoor air temperature.\n",
    "    - outdoor_temp_col (str): Column name for outdoor air temperature.\n",
    "    - device_id (str): Identifier for the device (used in results output).\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A dataframe containing regression results.\n",
    "    \"\"\"\n",
    "    # Extract independent and dependent variables\n",
    "    X = df[outdoor_temp_col]\n",
    "    y = df[indoor_temp_col]\n",
    "    \n",
    "    # Add a constant for the intercept\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Perform linear regression\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    r_squared = model.rsquared\n",
    "    p_value = model.f_pvalue\n",
    "    \n",
    "    # Get regression coefficients\n",
    "    intercept = model.params['const']\n",
    "    slope = model.params[outdoor_temp_col]\n",
    "    equation = f\"y = {intercept:.4f} + {slope:.4f}*x\"\n",
    "    \n",
    "    # Create a results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        '设备ID': [device_id],\n",
    "        'R²': [r_squared],\n",
    "        'p值': [p_value],\n",
    "        '回归方程': [equation]\n",
    "    })\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(df[outdoor_temp_col], df[indoor_temp_col], label='Data Points', color='#A4D9D7', alpha=0.5)\n",
    "    plt.plot(df[outdoor_temp_col], intercept + slope * df[outdoor_temp_col], color='#025F76', label='Regression Line')\n",
    "    \n",
    "    # Customize plot with Arial font and larger labels\n",
    "    plt.xlabel('Outdoor air temperature (°C)', fontsize=16, fontname='Arial')\n",
    "    plt.ylabel('Indoor air temperature (°C)', fontsize=16, fontname='Arial')\n",
    "    plt.xticks(fontsize=15, fontname='Arial')\n",
    "    plt.yticks(fontsize=15, fontname='Arial')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Display regression equation, R², and p-value on the plot\n",
    "    plt.text(\n",
    "        0.05, 0.95, \n",
    "        f\"Equation: {equation}\\nR² = {r_squared:.4f}\\nP-value = {p_value:.4e}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=12, \n",
    "        fontname='Arial', \n",
    "        verticalalignment='top',\n",
    "        bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8)\n",
    "    )\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, format='png', dpi=400)\n",
    "        print(f\"Saved plot to {save_path}\")\n",
    "    plt.show()        \n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "# Main processing function\n",
    "def process_device_data(device_id, room_type, input_file, output_folder, \n",
    "                        time_col='rawtime', state_col='Operational_status', \n",
    "                        temp_col='Setpoint', sleep_col='Sleep_period', stable_col='Stable_period',\n",
    "                        indoor_temp_col='Tin', outdoor_temp_col='Tout'):\n",
    "    \"\"\"\n",
    "    Process a single device's data based on its room type.\n",
    "\n",
    "    Parameters:\n",
    "    - device_id (str): The device ID.\n",
    "    - room_type (str): Room type (e.g., Bedroom, Livingroom+non-work, Mixedroom+work).\n",
    "    - input_file (str): Path to the input Excel file for the device.\n",
    "    - output_folder (str): Output folder path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(input_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {input_file}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 1: Mark stable and sleep periods\n",
    "    df = mark_stable_and_sleep_periods(df, state_col=state_col, temp_col=temp_col, time_col=time_col,\n",
    "                                       stable_col=stable_col, sleep_col=sleep_col)\n",
    "\n",
    "    # Step 2: Process based on room type\n",
    "    if room_type == 'Bedroom':\n",
    "        print(f\"Processing Bedroom data for ID {device_id}...\")\n",
    "        hourly_avg_sleep = sleepextract_and_average_stable_data(df, state_col=state_col, sleep_col=sleep_col, \n",
    "                                                                time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        output_file = os.path.join(output_folder, f\"{device_id}_sleep_hourly_average.xlsx\")\n",
    "        hourly_avg_sleep.to_excel(output_file, index=False)\n",
    "\n",
    "    elif 'Livingroom' in room_type:\n",
    "        print(f\"Processing Livingroom data for ID {device_id}...\")\n",
    "        hourly_avg = extract_and_average_stable_data(df, stable_col=stable_col, sleep_col=sleep_col, \n",
    "                                                     time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        hourly_avg_file = os.path.join(output_folder, f\"{device_id}_wake_hourly_average.xlsx\")\n",
    "        hourly_avg.to_excel(hourly_avg_file, index=False)\n",
    "        perform_linear_regression_and_plot(hourly_avg, indoor_temp_col=indoor_temp_col, \n",
    "                                           outdoor_temp_col=outdoor_temp_col, device_id=device_id, \n",
    "                                           output_path=output_folder, period='wake')\n",
    "\n",
    "    elif 'Mixedroom' in room_type:\n",
    "        print(f\"Processing Mixedroom data for ID {device_id}...\")\n",
    "        # Non-sleep data processing\n",
    "        hourly_avg = extract_and_average_stable_data(df, stable_col=stable_col, sleep_col=sleep_col, \n",
    "                                                     time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        hourly_avg_file = os.path.join(output_folder, f\"{device_id}_wake_hourly_average.xlsx\")\n",
    "        hourly_avg.to_excel(hourly_avg_file, index=False)\n",
    "        perform_linear_regression_and_plot(hourly_avg, indoor_temp_col=indoor_temp_col, \n",
    "                                           outdoor_temp_col=outdoor_temp_col, device_id=device_id, \n",
    "                                           output_path=output_folder, period='wake')\n",
    "        # Sleep data processing\n",
    "        hourly_avg_sleep = sleepextract_and_average_stable_data(df, state_col=state_col, sleep_col=sleep_col, \n",
    "                                                                time_col=time_col, target_cols=[indoor_temp_col, outdoor_temp_col])\n",
    "        sleep_avg_file = os.path.join(output_folder, f\"{device_id}_sleep_hourly_average.xlsx\")\n",
    "        hourly_avg_sleep.to_excel(sleep_avg_file, index=False)\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown room type for ID {device_id}. Skipping...\")\n",
    "\n",
    "process_device_data(\n",
    "    device_id='Device123',\n",
    "    room_type='Livingroom+non-work',\n",
    "    input_file='/path/to/input/Device123.xlsx',\n",
    "    output_folder='/path/to/output'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63afa9b-fc84-4f84-8a6e-cb7c37cc7a9c",
   "metadata": {},
   "source": [
    "## Comfort indoor air temperature setting schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd809588-6785-4e27-abfc-5ced71b1da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# Function to process Bedroom schedules\n",
    "def process_sleep_schedules(\n",
    "    id_cluster_file_path,\n",
    "    raw_data_folder_path,\n",
    "    output_folder_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Process sleep schedules for each device based on ID and save the results.\n",
    "\n",
    "    Parameters:\n",
    "    - id_cluster_file_path (str): Path to the Excel file containing IDs and clusters.\n",
    "    - raw_data_folder_path (str): Path to the folder containing raw data files.\n",
    "    - output_folder_path (str): Path to the folder where the results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Read the ID and cluster information\n",
    "    id_cluster_df = pd.read_excel(id_cluster_file_path)\n",
    "    \n",
    "    # Convert the ID column to string to avoid '.0' issue\n",
    "    id_cluster_df['ID'] = id_cluster_df['ID'].astype(str).str.replace('.0', '', regex=False)\n",
    "    \n",
    "    # Iterate over each ID in the DataFrame\n",
    "    for _, row in id_cluster_df.iterrows():\n",
    "        device_id = row['ID']\n",
    "        raw_data_file = f\"{device_id}_labeled_hourly_average.xlsx\"\n",
    "        raw_data_path = os.path.join(raw_data_folder_path, raw_data_file)\n",
    "        \n",
    "        # Check if the raw data file exists\n",
    "        if not os.path.exists(raw_data_path):\n",
    "            print(f\"Raw data file for ID {device_id} not found. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load the raw data file\n",
    "        try:\n",
    "            df = pd.read_excel(raw_data_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {raw_data_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Filter data for sleep hours (22:00 - 08:00)\n",
    "        sleep_hours = ['22', '23', '0', '1', '2', '3', '4', '5', '6', '7']\n",
    "        sleep_data = df[df['Hour'].astype(str).isin(sleep_hours)]\n",
    "\n",
    "        if sleep_data.empty:\n",
    "            print(f\"No sleep data available for ID {device_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Adjust the hour column to increment labels by 1\n",
    "        sleep_data['Hour'] = sleep_data['Hour'].astype(str).apply(\n",
    "            lambda h: str((int(h) + 1) % 24) if h.isdigit() else h\n",
    "        )\n",
    "\n",
    "        # Save the sleep schedule to an Excel file\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        output_file_path = os.path.join(output_folder_path, f\"{device_id}_sleep_schedule.xlsx\")\n",
    "        try:\n",
    "            sleep_data.to_excel(output_file_path, index=False)\n",
    "            print(f\"Saved sleep schedule for ID {device_id} to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving sleep schedule for ID {device_id}: {e}\")\n",
    "\n",
    "def process_work_living_room_comfort(\n",
    "    id_cluster_file_path,\n",
    "    regression_file_path,\n",
    "    weather_data_file_path,\n",
    "    output_folder_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Process living room comfort temperature calculations for working samples based on ID.\n",
    "\n",
    "    Parameters:\n",
    "    - id_cluster_file_path (str): Path to the Excel file containing IDs and clusters.\n",
    "    - regression_file_path (str): Path to the regression results Excel file.\n",
    "    - weather_data_file_path (str): Path to the Excel file containing hourly outdoor temperatures.\n",
    "    - output_folder_path (str): Path to the folder where the results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Step 1: Read the ID and cluster information, filter for 'work' samples\n",
    "    try:\n",
    "        id_cluster_df = pd.read_excel(id_cluster_file_path)\n",
    "        work_samples = id_cluster_df[id_cluster_df['re_cluster'] == 'work']['ID'].astype(str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading ID cluster file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Read the regression equations\n",
    "    try:\n",
    "        regression_df = pd.read_excel(regression_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading regression file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Read the hourly outdoor temperature data\n",
    "    try:\n",
    "        weather_data_df = pd.read_excel(weather_data_file_path)\n",
    "        hourly_temperatures = weather_data_df['Dry']  # Use 'Dry' as the outdoor temperature column\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Process each device in the work_samples\n",
    "    for device_id in work_samples:\n",
    "        # Find the regression equation for the current device ID\n",
    "        regression_row = regression_df[regression_df['ID'].astype(str) == device_id]\n",
    "        if regression_row.empty:\n",
    "            print(f\"No regression equation found for ID {device_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        regression_equation = regression_row['regression equation'].values[0]\n",
    "\n",
    "        # Extract coefficients from the regression equation\n",
    "        match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "        if not match:\n",
    "            print(f\"Invalid regression equation format for ID {device_id}: {regression_equation}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        intercept = float(match.group(1))\n",
    "        slope = float(match.group(2))\n",
    "\n",
    "        # Step 5: Calculate comfort temperatures\n",
    "        comfort_temperatures = (intercept + slope * hourly_temperatures).round(1)\n",
    "\n",
    "        # Step 6: Add operational status and room type\n",
    "        weather_data_df['Comfort_Temperature'] = comfort_temperatures\n",
    "        weather_data_df['operational_status'] = np.where(\n",
    "            weather_data_df['Hour'].isin([13, 14, 19, 20, 21, 22]), \n",
    "            'on', \n",
    "            'off'\n",
    "        )\n",
    "        weather_data_df['room_type'] = 'Livingroom+work'\n",
    "\n",
    "        # Set Comfort_Temperature to NaN where operational status is 'off'\n",
    "        weather_data_df.loc[weather_data_df['operational_status'] == 'off', 'Comfort_Temperature'] = np.nan\n",
    "\n",
    "        # Step 7: Create the output DataFrame\n",
    "        comfort_df = weather_data_df[['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']]\n",
    "\n",
    "        # Step 8: Save the resulting DataFrame to an Excel file\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        output_file_path = os.path.join(output_folder_path, f\"{device_id}_comfort_temperature.xlsx\")\n",
    "        try:\n",
    "            comfort_df.to_excel(output_file_path, index=False)\n",
    "            print(f\"Saved comfort temperature data for ID {device_id} to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving comfort temperature data for ID {device_id}: {e}\")\n",
    "            \n",
    "def process_nonwork_living_room_comfort(\n",
    "    id_cluster_file_path,\n",
    "    regression_file_path,\n",
    "    weather_data_file_path,\n",
    "    output_folder_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Process comfort temperature schedules for Livingroom+non-work based on IDs.\n",
    "\n",
    "    Parameters:\n",
    "    - id_cluster_file_path (str): Path to the Excel file containing IDs and clusters.\n",
    "    - regression_file_path (str): Path to the regression results Excel file.\n",
    "    - weather_data_file_path (str): Path to the Excel file containing hourly outdoor temperatures.\n",
    "    - output_folder_path (str): Path to the folder where the results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Step 1: Read the ID and cluster information, filter for 'non-work' samples\n",
    "    try:\n",
    "        id_cluster_df = pd.read_excel(id_cluster_file_path)\n",
    "        nonwork_samples = id_cluster_df[id_cluster_df['re_cluster'] == 'non-work']['ID'].astype(str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading ID cluster file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Read the regression equations\n",
    "    try:\n",
    "        regression_df = pd.read_excel(regression_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading regression file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Read the hourly outdoor temperature data\n",
    "    try:\n",
    "        weather_data_df = pd.read_excel(weather_data_file_path)\n",
    "        hourly_temperatures = weather_data_df['Dry']  # Use 'Dry' as the outdoor temperature column\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Process each device in the non-work samples\n",
    "    for device_id in nonwork_samples:\n",
    "        # Find the regression equation for the current device ID\n",
    "        regression_row = regression_df[regression_df['ID'].astype(str) == device_id]\n",
    "        if regression_row.empty:\n",
    "            print(f\"No regression equation found for ID {device_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        regression_equation = regression_row['regression equation'].values[0]\n",
    "\n",
    "        # Extract coefficients from the regression equation\n",
    "        match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "        if not match:\n",
    "            print(f\"Invalid regression equation format for ID {device_id}: {regression_equation}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        intercept = float(match.group(1))\n",
    "        slope = float(match.group(2))\n",
    "\n",
    "        # Step 5: Calculate comfort temperatures\n",
    "        comfort_temperatures = (intercept + slope * hourly_temperatures).round(1)\n",
    "\n",
    "        # Step 6: Add operational status and room type\n",
    "        weather_data_df['Comfort_Temperature'] = comfort_temperatures\n",
    "        weather_data_df['operational_status'] = np.where(\n",
    "            weather_data_df['Hour'].isin(range(9, 23)),  # 09:00 to 22:00\n",
    "            'on',\n",
    "            'off'\n",
    "        )\n",
    "        weather_data_df['room_type'] = 'Livingroom+non-work'\n",
    "\n",
    "        # Set Comfort_Temperature to NaN where operational status is 'off'\n",
    "        weather_data_df.loc[weather_data_df['operational_status'] == 'off', 'Comfort_Temperature'] = np.nan\n",
    "\n",
    "        # Step 7: Create the output DataFrame\n",
    "        comfort_df = weather_data_df[['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']]\n",
    "\n",
    "        # Step 8: Save the resulting DataFrame to an Excel file\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        output_file_path = os.path.join(output_folder_path, f\"{device_id}_comfort_temperature.xlsx\")\n",
    "        try:\n",
    "            comfort_df.to_excel(output_file_path, index=False)\n",
    "            print(f\"Saved comfort temperature data for ID {device_id} to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving comfort temperature data for ID {device_id}: {e}\")\n",
    "\n",
    "def process_mixed_non_work_room_comfort(\n",
    "    id_cluster_file_path,\n",
    "    regression_file_path,\n",
    "    weather_data_file_path,\n",
    "    raw_data_folder_path,\n",
    "    output_folder_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Process comfort temperature schedules for Mixedroom+non-work based on ID.\n",
    "\n",
    "    Parameters:\n",
    "    - id_cluster_file_path (str): Path to the Excel file containing IDs and clusters.\n",
    "    - regression_file_path (str): Path to the regression results Excel file.\n",
    "    - weather_data_file_path (str): Path to the hourly outdoor temperatures file.\n",
    "    - raw_data_folder_path (str): Path to the folder containing raw sleep data for night-time calculations.\n",
    "    - output_folder_path (str): Path to the folder where the results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Step 1: Read ID and cluster information\n",
    "    try:\n",
    "        id_cluster_df = pd.read_excel(id_cluster_file_path)\n",
    "        nonwork_samples = id_cluster_df[id_cluster_df['re_cluster'] == 'non-work']['ID'].astype(str).str.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading ID cluster file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Read regression equations\n",
    "    try:\n",
    "        regression_df = pd.read_excel(regression_file_path)\n",
    "        regression_df['ID'] = regression_df['ID'].astype(str).str.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading regression file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Read hourly outdoor temperature data\n",
    "    try:\n",
    "        weather_data_df = pd.read_excel(weather_data_file_path)\n",
    "        hourly_temperatures = weather_data_df['Dry']\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Process each device in the non-work cluster\n",
    "    for device_id in nonwork_samples:\n",
    "        # Find regression equation for the current device ID\n",
    "        regression_row = regression_df[regression_df['ID'] == device_id]\n",
    "        if regression_row.empty:\n",
    "            print(f\"No regression equation found for ID {device_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        regression_equation = regression_row['regression equation'].values[0]\n",
    "\n",
    "        # Extract coefficients from the regression equation\n",
    "        match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "        if not match:\n",
    "            print(f\"Invalid regression equation format for ID {device_id}: {regression_equation}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        intercept = float(match.group(1))\n",
    "        slope = float(match.group(2))\n",
    "\n",
    "        # Step 5: Calculate daytime comfort temperatures\n",
    "        daytime_hours = range(8, 22)  # Daytime hours: 08:00 to 21:00\n",
    "        comfort_temperatures_day = intercept + slope * hourly_temperatures\n",
    "        comfort_df_day = weather_data_df[weather_data_df['Hour'].isin(daytime_hours)].copy()\n",
    "        comfort_df_day['Comfort_Temperature'] = comfort_temperatures_day.round(1)\n",
    "\n",
    "        # Step 6: Process nighttime comfort temperatures\n",
    "        raw_data_file = f\"{device_id}_labeled_hourly_average.xlsx\"\n",
    "        raw_data_path = os.path.join(raw_data_folder_path, raw_data_file)\n",
    "\n",
    "        if not os.path.exists(raw_data_path):\n",
    "            print(f\"Raw data file for ID {device_id} not found. Skipping nighttime calculations...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            night_data_df = pd.read_excel(raw_data_path)\n",
    "            comfort_df_night = sleep_schedule_generate(night_data_df, weather_data_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing night data for ID {device_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Step 7: Expand nighttime data across all days in the weather period\n",
    "        night_hours = ['22', '23', '0', '1', '2', '3', '4', '5', '6', '7']\n",
    "        comfort_df_night_expanded = []\n",
    "\n",
    "        for month in weather_data_df['Month'].unique():\n",
    "            for day in weather_data_df[weather_data_df['Month'] == month]['Day'].unique():\n",
    "                for hour_str in night_hours:\n",
    "                    hour = int(hour_str)\n",
    "                    temperature = comfort_df_night.loc[\n",
    "                        comfort_df_night['hour'] == hour_str, 'average_temperature'\n",
    "                    ].values[0]\n",
    "                    comfort_df_night_expanded.append({\n",
    "                        'Month': month,\n",
    "                        'Day': day,\n",
    "                        'Hour': hour,\n",
    "                        'Comfort_Temperature': round(temperature, 1)\n",
    "                    })\n",
    "\n",
    "        comfort_df_night_expanded = pd.DataFrame(comfort_df_night_expanded)\n",
    "\n",
    "        # Step 8: Combine daytime and expanded nighttime data\n",
    "        comfort_df = pd.concat([comfort_df_day, comfort_df_night_expanded], ignore_index=True)\n",
    "        comfort_df = comfort_df.sort_values(by=['Month', 'Day', 'Hour']).reset_index(drop=True)\n",
    "\n",
    "        # Step 9: Save the final comfort temperature data\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        output_file_path = os.path.join(output_folder_path, f\"{device_id}_comfort_temperature.xlsx\")\n",
    "        try:\n",
    "            comfort_df.to_excel(output_file_path, index=False)\n",
    "            print(f\"Saved combined comfort temperature data for ID {device_id} to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving comfort temperature data for ID {device_id}: {e}\")\n",
    "def process_mixed_work_room_comfort(\n",
    "    id_cluster_file_path,\n",
    "    regression_file_path,\n",
    "    weather_data_file_path,\n",
    "    raw_data_folder_path,\n",
    "    output_folder_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Process comfort temperature schedules for Mixedroom+work based on ID.\n",
    "\n",
    "    Parameters:\n",
    "    - id_cluster_file_path (str): Path to the Excel file containing IDs and clusters.\n",
    "    - regression_file_path (str): Path to the regression results Excel file.\n",
    "    - weather_data_file_path (str): Path to the Excel file containing hourly outdoor temperatures.\n",
    "    - raw_data_folder_path (str): Path to the folder containing raw sleep data for night-time calculations.\n",
    "    - output_folder_path (str): Path to the folder where the results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Step 1: Read ID and cluster information\n",
    "    try:\n",
    "        id_cluster_df = pd.read_excel(id_cluster_file_path)\n",
    "        work_samples = id_cluster_df[id_cluster_df['re_cluster'] == 'work']['ID'].astype(str).str.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading ID cluster file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Read regression equations\n",
    "    try:\n",
    "        regression_df = pd.read_excel(regression_file_path)\n",
    "        regression_df['ID'] = regression_df['ID'].astype(str).str.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading regression file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Read hourly outdoor temperature data\n",
    "    try:\n",
    "        weather_data_df = pd.read_excel(weather_data_file_path)\n",
    "        hourly_temperatures = weather_data_df['Dry']\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading weather data file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Process each device in the work cluster\n",
    "    for device_id in work_samples:\n",
    "        # Find regression equation for the current device ID\n",
    "        regression_row = regression_df[regression_df['ID'] == device_id]\n",
    "        if regression_row.empty:\n",
    "            print(f\"No regression equation found for ID {device_id}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        regression_equation = regression_row['regression equation'].values[0]\n",
    "\n",
    "        # Extract coefficients from the regression equation\n",
    "        match = re.search(r\"y\\s*=\\s*([\\d\\.\\-]+)\\s*\\+\\s*([\\d\\.\\-]+)\\s*\\*\\s*x\", regression_equation)\n",
    "        if not match:\n",
    "            print(f\"Invalid regression equation format for ID {device_id}: {regression_equation}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        intercept = float(match.group(1))\n",
    "        slope = float(match.group(2))\n",
    "\n",
    "        # Step 5: Calculate daytime comfort temperatures\n",
    "        daytime_hours = [12, 13, 18, 19, 20, 21]  # Selected daytime hours\n",
    "        comfort_temperatures_day = intercept + slope * hourly_temperatures\n",
    "        comfort_df_day = weather_data_df[weather_data_df['Hour'].isin(daytime_hours)].copy()\n",
    "        comfort_df_day['Comfort_Temperature'] = comfort_temperatures_day.round(1)\n",
    "        comfort_df_day['operational_status'] = 'on'\n",
    "\n",
    "        # Set operational status to 'off' and temperature to NaN for other hours\n",
    "        other_daytime_hours = [h for h in range(8, 22) if h not in daytime_hours]\n",
    "        other_df_day = weather_data_df[weather_data_df['Hour'].isin(other_daytime_hours)].copy()\n",
    "        other_df_day['Comfort_Temperature'] = np.nan\n",
    "        other_df_day['operational_status'] = 'off'\n",
    "\n",
    "        # Combine both on and off hours\n",
    "        comfort_df_day = pd.concat([comfort_df_day, other_df_day], ignore_index=True)\n",
    "\n",
    "        # Step 6: Process nighttime comfort temperatures\n",
    "        raw_data_file = f\"{device_id}_labeled_hourly_average.xlsx\"\n",
    "        raw_data_path = os.path.join(raw_data_folder_path, raw_data_file)\n",
    "\n",
    "        if not os.path.exists(raw_data_path):\n",
    "            print(f\"Raw data file for ID {device_id} not found. Skipping nighttime calculations...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            night_data_df = pd.read_excel(raw_data_path)\n",
    "            comfort_df_night = sleep_schedule_generate(night_data_df, weather_data_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing night data for ID {device_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Step 7: Combine day and night data\n",
    "        comfort_df = pd.concat([comfort_df_day, comfort_df_night], ignore_index=True)\n",
    "        comfort_df['room_type'] = 'Mixedroom+work'\n",
    "        comfort_df = comfort_df.drop_duplicates(subset=['Month', 'Day', 'Hour']).sort_values(by=['Month', 'Day', 'Hour']).reset_index(drop=True)\n",
    "\n",
    "        # Keep only necessary columns\n",
    "        columns_to_keep = ['Month', 'Day', 'Hour', 'Comfort_Temperature', 'operational_status', 'room_type']\n",
    "        comfort_df = comfort_df[columns_to_keep]\n",
    "\n",
    "        # Step 8: Save the final comfort temperature data\n",
    "        os.makedirs(output_folder_path, exist_ok=True)\n",
    "        output_file_path = os.path.join(output_folder_path, f\"{device_id}_comfort_temperature.xlsx\")\n",
    "        try:\n",
    "            comfort_df.to_excel(output_file_path, index=False)\n",
    "            print(f\"Saved combined comfort temperature data for ID {device_id} to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving comfort temperature data for ID {device_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275559b5-28b6-4065-b20f-eb053bd3e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_room_schedules(\n",
    "    room_type,\n",
    "    id_cluster_file_path,\n",
    "    regression_file_path,\n",
    "    weather_data_file_path,\n",
    "    raw_data_folder_path,\n",
    "    output_folder_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate schedules for different room types based on input data and regression results.\n",
    "\n",
    "    Parameters:\n",
    "    - room_type (str): Room type ('Bedroom', 'Livingroom+work', 'Livingroom+non-work', 'Mixedroom+work', 'Mixedroom+non-work').\n",
    "    - id_cluster_file_path (str): Path to the Excel file containing IDs and clusters.\n",
    "    - regression_file_path (str): Path to the regression results Excel file.\n",
    "    - weather_data_file_path (str): Path to the Excel file containing hourly outdoor temperatures.\n",
    "    - raw_data_folder_path (str): Path to the folder containing raw sleep data.\n",
    "    - output_folder_path (str): Path to the folder where the results will be saved.\n",
    "    \"\"\"\n",
    "    if room_type == 'Bedroom':\n",
    "        process_sleep_schedules(\n",
    "            id_cluster_file_path=id_cluster_file_path,\n",
    "            raw_data_folder_path=raw_data_folder_path,\n",
    "            output_folder_path=output_folder_path\n",
    "        )\n",
    "    elif room_type == 'Livingroom+work':\n",
    "        process_work_living_room_comfort(\n",
    "            id_cluster_file_path=id_cluster_file_path,\n",
    "            regression_file_path=regression_file_path,\n",
    "            weather_data_file_path=weather_data_file_path,\n",
    "            output_folder_path=output_folder_path\n",
    "        )\n",
    "    elif room_type == 'Livingroom+non-work':\n",
    "        process_nonwork_living_room_comfort(\n",
    "            id_cluster_file_path=id_cluster_file_path,\n",
    "            regression_file_path=regression_file_path,\n",
    "            weather_data_file_path=weather_data_file_path,\n",
    "            output_folder_path=output_folder_path\n",
    "        )\n",
    "    elif room_type == 'Mixedroom+non-work':\n",
    "        process_mixed_non_work_room_comfort(\n",
    "            id_cluster_file_path=id_cluster_file_path,\n",
    "            regression_file_path=regression_file_path,\n",
    "            weather_data_file_path=weather_data_file_path,\n",
    "            raw_data_folder_path=raw_data_folder_path,\n",
    "            output_folder_path=output_folder_path\n",
    "        )\n",
    "    elif room_type == 'Mixedroom+work':\n",
    "        process_mixed_work_room_comfort(\n",
    "            id_cluster_file_path=id_cluster_file_path,\n",
    "            regression_file_path=regression_file_path,\n",
    "            weather_data_file_path=weather_data_file_path,\n",
    "            raw_data_folder_path=raw_data_folder_path,\n",
    "            output_folder_path=output_folder_path\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Invalid room type: {room_type}. Please choose from 'Bedroom', 'Livingroom+work', 'Livingroom+non-work', 'Mixedroom+work', or 'Mixedroom+non-work'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
